{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: I utilized module 4.6, the Wikipedia/Trains starter code provided for \"LDA\" class, and https://collab.its.virginia.edu/access/lessonbuilder/item/1926886/group/d0d365cf-c603-49dc-a1e3-be22940a5921/Textbooks/blei03a.pdf to complete this problem. I also consulted with classmate Geoff Hansen to compare our posterior distributions in P1a. and adjusted my answer since I had previously calculated the posterior distribution of words given particular topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1a. ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](HW5_P1_a.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The desired posterior distribution is P($\\theta$, z | w, $\\alpha$, $\\beta$). As described in https://collab.its.virginia.edu/access/lessonbuilder/item/1926886/group/d0d365cf-c603-49dc-a1e3-be22940a5921/Textbooks/blei03a.pdf, the problem with inferring the posterior distribution of latent variables is that the problem becomes intractable due to normalization over the sheer size of words/topics possible. Variational approximation yields a tractable solution because it avoids the computational complexity of sampling, but also provides a more accurate answer than conjugate priors (which are highly uncertain)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1b. ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](HW5_P1_a.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation (LDA) Examples\n",
    "\n",
    "This notebook explores using LDA for pages in Wikipedia and for analyis of the narratives in train accident reports. These examples show how the LDA method is possible thanks to variational approximation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ngk3pf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ngk3pf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#!pip install nltk.corpus\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import wikipedia\n",
    "import nltk\n",
    "import json\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "# Set stop words\n",
    "stopWords = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This preprocessing step just removes stopwords\n",
    "\n",
    "def preprocessor(text):\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return (\" \").join([word for word in tokens if word not in stopWords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LDA_wikipedia:\n",
    "    \"\"\"Creates a class for Latent Dirichlet Allocation using summaries from Wikipedia\n",
    "    Input:\n",
    "        title_list = list of titles for Wikipedia pages\n",
    "        N_topics = number of topics for LDA to produce\n",
    "        N_words = the number of words to show in a topic\n",
    "        new_title = title for a new page not in the training s\n",
    "    Methods:\n",
    "        Topics = Outputs the list of topics in the selected Wikipedia pages as a dataframe\n",
    "        Predict_Topics\n",
    "            Input: New titles for Wikipedia pages\n",
    "            Output: A dataframe with the probabilities for topics for each new page\"\"\"\n",
    "    \n",
    "    def __init__(self, title_list, N_topics=3, N_words = 10):\n",
    "        # initialize variables\n",
    "        self.title_list = title_list\n",
    "        self.N_topics = N_topics\n",
    "        self.N_words = N_words\n",
    "        # start with an empty corpus\n",
    "        self.corpus = list()\n",
    "    \n",
    "        # Get the summary pages for the given titles\n",
    "        # then preprocess\n",
    "        for title in self.title_list:\n",
    "            page = wikipedia.page(title)\n",
    "            self.corpus.append(preprocessor(page.summary))\n",
    "        \n",
    "        # Get the matrix of word counts for the pages\n",
    "        # this will be the input the the LDA\n",
    "        self.countVectorizer = CountVectorizer(stop_words='english')\n",
    "        self.termFrequency = self.countVectorizer.fit_transform(self.corpus)\n",
    "        self.Words = self.countVectorizer.get_feature_names()\n",
    "        \n",
    "    def Topics(self):\n",
    "        # Obtain the estimates for the LDA model \n",
    "        self.lda = LatentDirichletAllocation(n_components=self.N_topics)\n",
    "        self.lda.fit(self.termFrequency)\n",
    "        \n",
    "        # Obtain the list of the top N_words in the topics\n",
    "        topics = list()\n",
    "        for topic in self.lda.components_:\n",
    "            topics.append([self.Words[i] for i in topic.argsort()[:-self.N_words - 1:-1]])\n",
    "            \n",
    "        # Create a list of column names, Words, for the dataframe output\n",
    "        cols = list()\n",
    "        for i in range(self.N_words):\n",
    "            cols.append(\"Word \"+(str(i)))\n",
    "        \n",
    "        # Create a dataframe with the topic no. and the words in each topic \n",
    "        # output this dataframe\n",
    "        Topics_df = pd.DataFrame(topics, columns = cols)\n",
    "        Topics_df.index.name = \"Topics\"\n",
    "        return Topics_df  \n",
    "    \n",
    "    def Predict_Topics(self, new_title_list):\n",
    "        # Get the new titles for the new pages\n",
    "        # and the number of new pages \n",
    "        self.new_title_list = new_title_list\n",
    "        N_new_docs = len(new_title_list)\n",
    "        \n",
    "        # For each of the new titles get the summary page in Wikipedia\n",
    "        # then obtain the estimate probabilities for each of the topics\n",
    "        # discovered in the training set for each of the new pages\n",
    "        new_doc_topics = list()\n",
    "        for title in self.new_title_list:\n",
    "            new_page = wikipedia.page(title)\n",
    "            new_doc = preprocessor(new_page.summary)\n",
    "            new_doc_topics.append(self.lda.transform(self.countVectorizer.transform([new_doc])))\n",
    "            \n",
    "        # Recast the list of topic probabilities as an array of size number of no. pages X no. of topics\n",
    "        new_doc_topics = np.array(new_doc_topics).reshape(N_new_docs, self.N_topics)\n",
    "        # Create labels for the columns in the output dataframe\n",
    "        cols = list()\n",
    "        for i in range(self.N_topics):\n",
    "            cols.append(\"Topic \"+(str(i)))\n",
    "            \n",
    "        # Create the dataframe whose rows contain the topic probabilities for specific Wikipedia pages\n",
    "        New_Page_df = pd.DataFrame(new_doc_topics, columns = cols )\n",
    "        New_Page_df.insert(0, 'Page Name', self.new_title_list)\n",
    "        return New_Page_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>published</td>\n",
       "      <td>novel</td>\n",
       "      <td>war</td>\n",
       "      <td>works</td>\n",
       "      <td>story</td>\n",
       "      <td>writer</td>\n",
       "      <td>novels</td>\n",
       "      <td>short</td>\n",
       "      <td>american</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>woolf</td>\n",
       "      <td>english</td>\n",
       "      <td>london</td>\n",
       "      <td>literature</td>\n",
       "      <td>work</td>\n",
       "      <td>published</td>\n",
       "      <td>literary</td>\n",
       "      <td>known</td>\n",
       "      <td>women</td>\n",
       "      <td>works</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>novels</td>\n",
       "      <td>novel</td>\n",
       "      <td>american</td>\n",
       "      <td>published</td>\n",
       "      <td>literary</td>\n",
       "      <td>dickens</td>\n",
       "      <td>fitzgerald</td>\n",
       "      <td>faulkner</td>\n",
       "      <td>known</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word 0   Word 1    Word 2      Word 3    Word 4     Word 5  \\\n",
       "Topics                                                                  \n",
       "0       published    novel       war       works     story     writer   \n",
       "1           woolf  english    london  literature      work  published   \n",
       "2          novels    novel  american   published  literary    dickens   \n",
       "\n",
       "            Word 6    Word 7    Word 8 Word 9  \n",
       "Topics                                         \n",
       "0           novels     short  american  world  \n",
       "1         literary     known     women  works  \n",
       "2       fitzgerald  faulkner     known  short  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example with famous authors\n",
    "\n",
    "authors = ['\"Charles Dickens\"', '\"Graham Greene\"', '\"Jane Eyre\"', '\"Jane Austen\"', '\"George Orwell\"',\n",
    "          '\"Charlotte Bronte\"', '\"Virginia Woolf\"', '\"Evelyn Waugh\"',\n",
    "           '\"Mark Twain\"', '\"Scott Fitzgerald\"','\"Ernest Hemingway\"', '\"William Faulkner\"', \n",
    "          '\"Kurt Vonnegut\"','\"Harper Lee\"', '\"Edgar Allen Poe\"', '\"John Steinbeck\"' ]\n",
    "\n",
    "# This is a small data set, so try 3 topics\n",
    "ld_authors = LDA_wikipedia(title_list = authors, N_topics =3)\n",
    "ld_authors.Topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page Name</th>\n",
       "      <th>Topic 0</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Toni Morrison\"</td>\n",
       "      <td>0.424357</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.568766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Stephen King\"</td>\n",
       "      <td>0.314499</td>\n",
       "      <td>0.089272</td>\n",
       "      <td>0.596229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Page Name   Topic 0   Topic 1   Topic 2\n",
       "0  \"Toni Morrison\"  0.424357  0.006877  0.568766\n",
       "1   \"Stephen King\"  0.314499  0.089272  0.596229"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how it does with two famous contemporary authors\n",
    "ld_authors.Predict_Topics(['\"Toni Morrison\"', '\"Stephen King\"'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Accident Narratives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train accident narratives are in a json file\n",
    "# Read the JSON file with the narratives and convert to a list for the LDA analysis\n",
    "\n",
    "\n",
    "with open('TrainNarratives.txt') as json_file:  \n",
    "    Narrative_dict = json.load(json_file)\n",
    "    \n",
    "train_reports = list(Narrative_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LDA_trains:\n",
    "    \"\"\"Creates a class for Latent Dirichlet Allocation using summaries from Wikipedia\n",
    "    Input:\n",
    "        reports = list of narratives from accident reports\n",
    "        N_topics = number of topics for LDA to produce\n",
    "        N_words = the number of words to show in a topic\n",
    "        new_report = narrative for a new accident report not in the training set\n",
    "    Methods:\n",
    "        Topics = Print the list of topics in the selected narratives\n",
    "        Predict_Topics = Show the predicted probabilities for topics for a new accident narrative\"\"\"\n",
    "    \n",
    "    def __init__(self, reports, N_topics=3, N_words = 10):\n",
    "        # the narrative reports\n",
    "        self.reports = reports\n",
    "        # initialize variables\n",
    "        self.N_topics = N_topics\n",
    "        self.N_words = N_words\n",
    "        \n",
    "        # Get the word counts in the reports\n",
    "        self.countVectorizer = CountVectorizer(stop_words='english')\n",
    "        self.termFrequency = self.countVectorizer.fit_transform(self.reports)\n",
    "        self.Words = self.countVectorizer.get_feature_names()\n",
    "        \n",
    "    def Topics(self):\n",
    "        # Obtain the estimates for the LDA model\n",
    "        \n",
    "        ### Your code here\n",
    "        self.lda = LatentDirichletAllocation(n_components=self.N_topics)\n",
    "        self.lda.fit(self.termFrequency)\n",
    "        \n",
    "        # For each of the topics in the model add the top N_words the list of topics\n",
    "        ### Your code here\n",
    "        topics = list()\n",
    "        for topic in self.lda.components_:\n",
    "            topics.append([self.Words[i] for i in topic.argsort()[:-self.N_words - 1:-1]])\n",
    "        \n",
    "        # Create column names for the output matrix\n",
    "        cols = list()\n",
    "        for i in range(self.N_words):\n",
    "            cols.append(\"Word \"+(str(i)))\n",
    "            \n",
    "        # Create a dataframe with the topic no. and the words in each topic \n",
    "        # output this dataframe \n",
    "        Topics_df = pd.DataFrame(topics, columns = cols)\n",
    "        Topics_df.index.name = \"Topics\"  ### Your code here\n",
    "        return Topics_df\n",
    "    \n",
    "    def Predict_Topics(self, new_reports):\n",
    "        self.new_reports = new_reports\n",
    "        \n",
    "        # Get the list of new accident report narratives\n",
    "        # and the number of new narratives\n",
    "        N_new_reports = len(self.new_reports)\n",
    "        \n",
    "        \n",
    "        # For each of the new narratives \n",
    "        # obtain the estimated probabilities for each of the topics\n",
    "        # in each of the new narratives as estimated by the LDA results\n",
    "        # on the training set \n",
    "        new_report_topics = list()\n",
    "        ### Your code here        \n",
    "        for title in self.new_reports:\n",
    "            new_page = title\n",
    "            new_doc = preprocessor(new_page)\n",
    "            new_report_topics.append(self.lda.transform(self.countVectorizer.transform([new_doc])))\n",
    "        \n",
    "        \n",
    "        # Recast the list of probabilities for topics as an array \n",
    "        # of size no. of new reports X no. of topics\n",
    "        new_report_topics = np.array(new_report_topics).reshape(N_new_reports, self.N_topics)\n",
    "        \n",
    "        # Create column names for the output dataframe\n",
    "        cols = list()\n",
    "        ### Your code here        \n",
    "        \n",
    "        for i in range(self.N_topics):\n",
    "            cols.append(\"Topic \"+(str(i)))\n",
    "        \n",
    "        # Create the dataframe whose rows contain topic probabilities for \n",
    "        # specificed narratives/reports  \n",
    "        New_Reports_df = pd.DataFrame(new_report_topics, columns = cols )\n",
    "        New_Reports_df.insert(0, 'Report Name', self.new_reports)\n",
    "        \n",
    "        return New_Reports_df\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNITS 231-281 ( BACK TO BACK ) WERE COMING INTO UP DEISEL SHOP WHEN THE LEFT WHEEL OF 281 RODE OVER RECENTLY REPAIRED SWITCH PLATE AND DERAILED . THE CAUSE WAS DETERMINED TO BE THE TRACK TELEMETRY IN THAT IT WAS TOO SHARP OF A CURVE .\n",
      "UNITS 231-281(BACK TO BACK)  WERE COMING INTO UP DEISEL SHOP  WHEN THE LEFT WHEEL OF 281 RODE OVER RECENTLY REPAIRED SWITCH PLATE AND DERAILED. THE CAUSE WAS DETERMINED TO BE THE TRACK TELEMETRY IN THAT IT WAS TOO SHARP OF A CURVE.\n"
     ]
    }
   ],
   "source": [
    "   # For each of the new narratives \n",
    "        # obtain the estimated probabilities for each of the topics\n",
    "        # in each of the new narratives as estimated by the LDA results\n",
    "        # on the training set     \n",
    "new_report_topics = list()\n",
    "new_reports=train_reports\n",
    "for title in new_reports[:1]:\n",
    "    new_page = title\n",
    "    new_doc = preprocessor(new_page)\n",
    "    print(new_doc)\n",
    "    print(new_page)\n",
    "    new_report_topics.append(self.lda.transform(self.countVectorizer.transform([new_doc])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>derailed</td>\n",
       "      <td>hazardous</td>\n",
       "      <td>track</td>\n",
       "      <td>cars</td>\n",
       "      <td>materials</td>\n",
       "      <td>released</td>\n",
       "      <td>yard</td>\n",
       "      <td>pulling</td>\n",
       "      <td>railcars</td>\n",
       "      <td>leaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cars</td>\n",
       "      <td>track</td>\n",
       "      <td>car</td>\n",
       "      <td>crew</td>\n",
       "      <td>cut</td>\n",
       "      <td>train</td>\n",
       "      <td>end</td>\n",
       "      <td>derailed</td>\n",
       "      <td>shoving</td>\n",
       "      <td>conductor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>derailed</td>\n",
       "      <td>wide</td>\n",
       "      <td>track</td>\n",
       "      <td>cars</td>\n",
       "      <td>gauge</td>\n",
       "      <td>gage</td>\n",
       "      <td>fuel</td>\n",
       "      <td>rail</td>\n",
       "      <td>pulling</td>\n",
       "      <td>wheel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>struck</td>\n",
       "      <td>track</td>\n",
       "      <td>damage</td>\n",
       "      <td>locomotive</td>\n",
       "      <td>unit</td>\n",
       "      <td>operator</td>\n",
       "      <td>vehicle</td>\n",
       "      <td>equipment</td>\n",
       "      <td>humping</td>\n",
       "      <td>crossing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rail</td>\n",
       "      <td>cars</td>\n",
       "      <td>switch</td>\n",
       "      <td>derailed</td>\n",
       "      <td>point</td>\n",
       "      <td>broken</td>\n",
       "      <td>lead</td>\n",
       "      <td>broke</td>\n",
       "      <td>causing</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>switch</td>\n",
       "      <td>track</td>\n",
       "      <td>car</td>\n",
       "      <td>crew</td>\n",
       "      <td>cars</td>\n",
       "      <td>derailed</td>\n",
       "      <td>yard</td>\n",
       "      <td>lined</td>\n",
       "      <td>lead</td>\n",
       "      <td>movement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>derailed</td>\n",
       "      <td>cars</td>\n",
       "      <td>track</td>\n",
       "      <td>loads</td>\n",
       "      <td>pulling</td>\n",
       "      <td>car</td>\n",
       "      <td>ns</td>\n",
       "      <td>head</td>\n",
       "      <td>empties</td>\n",
       "      <td>east</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train</td>\n",
       "      <td>derailed</td>\n",
       "      <td>car</td>\n",
       "      <td>cars</td>\n",
       "      <td>track</td>\n",
       "      <td>mph</td>\n",
       "      <td>curve</td>\n",
       "      <td>speed</td>\n",
       "      <td>rail</td>\n",
       "      <td>excessive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>track</td>\n",
       "      <td>bnsf</td>\n",
       "      <td>cars</td>\n",
       "      <td>damage</td>\n",
       "      <td>train</td>\n",
       "      <td>car</td>\n",
       "      <td>derailed</td>\n",
       "      <td>end</td>\n",
       "      <td>job</td>\n",
       "      <td>pulling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train</td>\n",
       "      <td>car</td>\n",
       "      <td>derailed</td>\n",
       "      <td>emergency</td>\n",
       "      <td>cars</td>\n",
       "      <td>mp</td>\n",
       "      <td>crew</td>\n",
       "      <td>damage</td>\n",
       "      <td>went</td>\n",
       "      <td>rail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word 0     Word 1    Word 2      Word 3     Word 4    Word 5  \\\n",
       "Topics                                                                   \n",
       "0       derailed  hazardous     track        cars  materials  released   \n",
       "1           cars      track       car        crew        cut     train   \n",
       "2       derailed       wide     track        cars      gauge      gage   \n",
       "3         struck      track    damage  locomotive       unit  operator   \n",
       "4           rail       cars    switch    derailed      point    broken   \n",
       "5         switch      track       car        crew       cars  derailed   \n",
       "6       derailed       cars     track       loads    pulling       car   \n",
       "7          train   derailed       car        cars      track       mph   \n",
       "8          track       bnsf      cars      damage      train       car   \n",
       "9          train        car  derailed   emergency       cars        mp   \n",
       "\n",
       "          Word 6     Word 7    Word 8     Word 9  \n",
       "Topics                                            \n",
       "0           yard    pulling  railcars    leaking  \n",
       "1            end   derailed   shoving  conductor  \n",
       "2           fuel       rail   pulling      wheel  \n",
       "3        vehicle  equipment   humping   crossing  \n",
       "4           lead      broke   causing        car  \n",
       "5           yard      lined      lead   movement  \n",
       "6             ns       head   empties       east  \n",
       "7          curve      speed      rail  excessive  \n",
       "8       derailed        end       job    pulling  \n",
       "9           crew     damage      went       rail  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_train = LDA_trains(reports = train_reports, N_topics = 10, N_words = 10)\n",
    "lda_train.Topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Report Name</th>\n",
       "      <th>Topic 0</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>Topic 6</th>\n",
       "      <th>Topic 7</th>\n",
       "      <th>Topic 8</th>\n",
       "      <th>Topic 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNITS 231-281(BACK TO BACK)  WERE COMING INTO ...</td>\n",
       "      <td>0.229142</td>\n",
       "      <td>0.004546</td>\n",
       "      <td>0.004547</td>\n",
       "      <td>0.004546</td>\n",
       "      <td>0.464354</td>\n",
       "      <td>0.274677</td>\n",
       "      <td>0.004547</td>\n",
       "      <td>0.004547</td>\n",
       "      <td>0.004546</td>\n",
       "      <td>0.004547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENGINE 286 CAUGHT FIRE AT THE SPRINGFIELD, MA ...</td>\n",
       "      <td>0.009092</td>\n",
       "      <td>0.114051</td>\n",
       "      <td>0.207441</td>\n",
       "      <td>0.009093</td>\n",
       "      <td>0.009092</td>\n",
       "      <td>0.009093</td>\n",
       "      <td>0.009093</td>\n",
       "      <td>0.009093</td>\n",
       "      <td>0.009092</td>\n",
       "      <td>0.614861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN NO.#4 WITH ENGS 83/11/90/44 AND 11 CARS ...</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.453532</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.527859</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.002326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WHILE SHOVING TRAIN 624 SOUTH ON #30 TRACK AT ...</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.943737</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.006252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN 786 WAS STRUCK BY A FALLING TREE SOUTH O...</td>\n",
       "      <td>0.132671</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.354570</td>\n",
       "      <td>0.442744</td>\n",
       "      <td>0.010001</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.010001</td>\n",
       "      <td>0.010003</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.010005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ENGINE 4403 OF NJT TRAIN 3204 HAD 90% OLD BREA...</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.954998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGR CREW DELIVERED CARS TO BNSF AT BNSF YARD A...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.753667</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.131328</td>\n",
       "      <td>0.099093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TRAIN #263 CAME INTO RUTHLAND YARD AND THEY WE...</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.981245</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.002084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CREW WAS SHOVING A CUT OF CARS EASTWARD TOWARD...</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>0.288334</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>0.155399</td>\n",
       "      <td>0.529338</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>0.003848</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>0.003847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WHILE BUILDING TAIN, 1130 TRIMMER DERAILED FOU...</td>\n",
       "      <td>0.007694</td>\n",
       "      <td>0.007694</td>\n",
       "      <td>0.514267</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>0.424184</td>\n",
       "      <td>0.007694</td>\n",
       "      <td>0.007696</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>0.007693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Report Name   Topic 0   Topic 1  \\\n",
       "0  UNITS 231-281(BACK TO BACK)  WERE COMING INTO ...  0.229142  0.004546   \n",
       "1  ENGINE 286 CAUGHT FIRE AT THE SPRINGFIELD, MA ...  0.009092  0.114051   \n",
       "2  TRAIN NO.#4 WITH ENGS 83/11/90/44 AND 11 CARS ...  0.002326  0.002326   \n",
       "3  WHILE SHOVING TRAIN 624 SOUTH ON #30 TRACK AT ...  0.006252  0.006252   \n",
       "4  TRAIN 786 WAS STRUCK BY A FALLING TREE SOUTH O...  0.132671  0.010002   \n",
       "5  ENGINE 4403 OF NJT TRAIN 3204 HAD 90% OLD BREA...  0.005000  0.005000   \n",
       "6  AGR CREW DELIVERED CARS TO BNSF AT BNSF YARD A...  0.002273  0.753667   \n",
       "7  TRAIN #263 CAME INTO RUTHLAND YARD AND THEY WE...  0.002084  0.981245   \n",
       "8  CREW WAS SHOVING A CUT OF CARS EASTWARD TOWARD...  0.003847  0.288334   \n",
       "9  WHILE BUILDING TAIN, 1130 TRIMMER DERAILED FOU...  0.007694  0.007694   \n",
       "\n",
       "    Topic 2   Topic 3   Topic 4   Topic 5   Topic 6   Topic 7   Topic 8  \\\n",
       "0  0.004547  0.004546  0.464354  0.274677  0.004547  0.004547  0.004546   \n",
       "1  0.207441  0.009093  0.009092  0.009093  0.009093  0.009093  0.009092   \n",
       "2  0.002326  0.002326  0.002326  0.453532  0.002326  0.527859  0.002326   \n",
       "3  0.006251  0.006251  0.006251  0.943737  0.006252  0.006251  0.006251   \n",
       "4  0.354570  0.442744  0.010001  0.010002  0.010001  0.010003  0.010002   \n",
       "5  0.005000  0.005000  0.005001  0.005000  0.005000  0.005000  0.005000   \n",
       "6  0.002273  0.002273  0.002273  0.002274  0.002273  0.002273  0.131328   \n",
       "7  0.002084  0.002084  0.002084  0.002084  0.002084  0.002084  0.002084   \n",
       "8  0.003847  0.003847  0.155399  0.529338  0.003847  0.003848  0.003847   \n",
       "9  0.514267  0.007693  0.424184  0.007694  0.007696  0.007693  0.007693   \n",
       "\n",
       "    Topic 9  \n",
       "0  0.004547  \n",
       "1  0.614861  \n",
       "2  0.002326  \n",
       "3  0.006252  \n",
       "4  0.010005  \n",
       "5  0.954998  \n",
       "6  0.099093  \n",
       "7  0.002084  \n",
       "8  0.003847  \n",
       "9  0.007693  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_train.Predict_Topics(train_reports[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probabilities displayed here are the probabilities of per document topics (theta) for a given document, given the document's word distribution (w) with a given per-topic word distribution (beta), and the topic distribution for a given word (z)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A safety engineer could do several things with the information provided. First, he/she could examine the fluctuation of topic incidences for the most recent reports to see whether there are trending maintenance/user error issues that need to be addressed. For instance, in the second table, we can see that reports 6-8 all have 25%+ topic 1 associations. Examining the most common words within topic 1 in the first table, we can see that unique words for topic 1 include \"shoving\" \"crew\" and \"conductor,\" as well as \"derailment.\" This might lead the safety engineer to reexamine the number of personnel surrounding conductors or train crews, to avoid future derailments due to user error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
