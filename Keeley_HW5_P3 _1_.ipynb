{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1026014",
   "metadata": {},
   "source": [
    "## Problem 3 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ea1494",
   "metadata": {},
   "source": [
    "References: 22 NOV 2021 class recording; Wiecki notebook starter code provided"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140fa76c",
   "metadata": {},
   "source": [
    "### a. ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99196e76",
   "metadata": {},
   "source": [
    "Wiecki visualizes the label predictions with the highest uncertainty through a heatmap of standard deviations for the posterior distribution of predictions. By training our neural network on the label predictions with the highest degree of uncertainty, we could improve accuracy by allowing our model to be extremely good at differentiating \"edge cases\" between class label 0 and 1. By extension, this might improve the overall accuracy of our model. I would implement this suggestion by rerunning the code, but only using a randomized sample of the highest uncertainty datapoints (above a certain standard deviation threshold within the largest standard deviation segment of the visualization)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69528e1e",
   "metadata": {},
   "source": [
    "### b. ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f28c86",
   "metadata": {},
   "source": [
    "The example neural network has an architecture consisting of two hidden layers (above the visible layer), each containing five neurons. The weights between these neurons represent the strength of relationships between the visible layer and latent variables, represented by neurons. Therefore, the uncertainty estimates of the weights (visualized through a forest plot in Dr. Brown's lecture) are a credible interval with which we can assess the reliability of these relationship estimates. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e023a14b",
   "metadata": {},
   "source": [
    "### c. ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6015af",
   "metadata": {},
   "source": [
    "Gaussian priors help regularize the weights of the example neural network by effetively serving as parameter constraints, bounding the spectrum of weights we are likely to see during formation of the network. This effectively serves as L2 regularization, preventing weights from overfitting to the training data without entirely removing them from the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd5fc4b",
   "metadata": {},
   "source": [
    "### d. ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d49e41",
   "metadata": {},
   "source": [
    "We use variational inference instead of sampling to estimate the posterior distribution of the network's weights to accommodate the computational complexity associated with expanding the neural network's architecture. MCMC sampling would slow down exponentially as our network scales up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afd9c95",
   "metadata": {},
   "source": [
    "### e. ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99ea30e",
   "metadata": {},
   "source": [
    "The results of changing the priors from Gaussian to Cauchy resulted in diminished accuracy of the neural network (~85%), as well as a hyperparameter that looks more linear than the previous iteration. This makes sense given that Cauchy distributions have fatter tails than Gaussian distributions, perhaps leading to a wider distribution of weights and increasing the uncertainty within the neural network's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bc42de",
   "metadata": {},
   "source": [
    "![](Cauchy_viz.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111e8dba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
